from __future__ import annotations

from typing import Any

import paddle.nn as nn

from ..ops import ConvNormActivation as ConvNormActivation

model_urls: Any

def create_activation_layer(act: Any): ...
def channel_shuffle(x: Any, groups: Any): ...

class InvertedResidual(nn.Layer):
    def __init__(self, in_channels: Any, out_channels: Any, stride: Any, activation_layer: Any = ...) -> None: ...
    def forward(self, inputs: Any): ...

class InvertedResidualDS(nn.Layer):
    def __init__(self, in_channels: Any, out_channels: Any, stride: Any, activation_layer: Any = ...) -> None: ...
    def forward(self, inputs: Any): ...

class ShuffleNetV2(nn.Layer):
    scale: Any = ...
    num_classes: Any = ...
    with_pool: Any = ...
    def __init__(self, scale: float = ..., act: str = ..., num_classes: int = ..., with_pool: bool = ...) -> None: ...
    def forward(self, inputs: Any): ...

def shufflenet_v2_x0_25(pretrained: bool = ..., **kwargs: Any): ...
def shufflenet_v2_x0_33(pretrained: bool = ..., **kwargs: Any): ...
def shufflenet_v2_x0_5(pretrained: bool = ..., **kwargs: Any): ...
def shufflenet_v2_x1_0(pretrained: bool = ..., **kwargs: Any): ...
def shufflenet_v2_x1_5(pretrained: bool = ..., **kwargs: Any): ...
def shufflenet_v2_x2_0(pretrained: bool = ..., **kwargs: Any): ...
def shufflenet_v2_swish(pretrained: bool = ..., **kwargs: Any): ...
