from __future__ import annotations

from collections import OrderedDict
from typing import Any

class LRUSharedCache(OrderedDict):
    limit: int = ...
    def __init__(self) -> None: ...
    def get(self, key: Any): ...
    def __setitem__(self, key: Any, value: Any) -> None: ...

shared_cache: Any

def cuda_from_cache(key: Any): ...
def rebuild_tensor(cls, lodtensor: Any, metadata: Any): ...
def reduce_tensor(tensor: Any): ...
def rebuild_lodtensor_filename(cls, ipc_name: Any, size: Any, type_idx: Any, dims: Any, lod: Any): ...
def rebuild_cuda_tensor(
    cls, handle: Any, offset_bytes: Any, size: Any, type_idx: Any, dims: Any, lod: Any, device_idx: Any
): ...
def rebuild_lodtensor_empty(cls): ...
def reduce_lodtensor(lodtensor: Any): ...
def init_reductions() -> None: ...
