from __future__ import annotations

from typing import Any, Optional

from .meta_optimizer_base import MetaOptimizerBase as MetaOptimizerBase

class AMPOptimizer(MetaOptimizerBase):
    inner_opt: Any = ...
    wrapped_opt: Any = ...
    meta_optimizers_white_list: Any = ...
    meta_optimizers_black_list: Any = ...
    def __init__(self, optimizer: Any) -> None: ...
    def backward(
        self,
        loss: Any,
        startup_program: Optional[Any] = ...,
        parameter_list: Optional[Any] = ...,
        no_grad_set: Optional[Any] = ...,
        callbacks: Optional[Any] = ...,
    ): ...
    def apply_gradients(self, params_grads: Any): ...
    def apply_optimize(self, loss: Any, startup_program: Any, params_grads: Any): ...
    def minimize_impl(
        self,
        loss: Any,
        startup_program: Optional[Any] = ...,
        parameter_list: Optional[Any] = ...,
        no_grad_set: Optional[Any] = ...,
    ): ...
    def amp_init(
        self, place: Any, scope: Optional[Any] = ..., test_program: Optional[Any] = ..., use_fp16_test: bool = ...
    ): ...
    def get_loss_scaling(self): ...
