from __future__ import annotations

from typing import Any, Optional

from paddle.fluid.framework import in_dygraph_mode as in_dygraph_mode

from ...fluid.data_feeder import check_dtype as check_dtype
from ...fluid.data_feeder import check_variable_and_dtype as check_variable_and_dtype
from ...fluid.dygraph.inplace_utils import (
    inplace_apis_in_dygraph_only as inplace_apis_in_dygraph_only,
)
from ...fluid.framework import convert_np_dtype_to_dtype_ as convert_np_dtype_to_dtype_
from ...fluid.layer_helper import LayerHelper as LayerHelper
from ...fluid.layers import sigmoid as sigmoid
from ...tensor.manipulation import chunk as chunk
from ...tensor.math import multiply as multiply
from ...tensor.math import tanh as tanh
from ...tensor.math import tanh_ as tanh_

def celu(x: Any, alpha: float = ..., name: Optional[Any] = ...): ...
def elu(x: Any, alpha: float = ..., name: Optional[Any] = ...): ...
def elu_(x: Any, alpha: float = ..., name: Optional[Any] = ...): ...
def gelu(x: Any, approximate: bool = ..., name: Optional[Any] = ...): ...
def hardshrink(x: Any, threshold: float = ..., name: Optional[Any] = ...): ...
def hardtanh(x: Any, min: Any = ..., max: float = ..., name: Optional[Any] = ...): ...
def hardsigmoid(x: Any, slope: float = ..., offset: float = ..., name: Optional[Any] = ...): ...
def hardswish(x: Any, name: Optional[Any] = ...): ...
def leaky_relu(x: Any, negative_slope: float = ..., name: Optional[Any] = ...): ...
def prelu(x: Any, weight: Any, data_format: str = ..., name: Optional[Any] = ...): ...
def relu(x: Any, name: Optional[Any] = ...): ...
def relu_(x: Any, name: Optional[Any] = ...): ...
def log_sigmoid(x: Any, name: Optional[Any] = ...): ...
def maxout(x: Any, groups: Any, axis: int = ..., name: Optional[Any] = ...): ...
def relu6(x: Any, name: Optional[Any] = ...): ...
def selu(x: Any, scale: float = ..., alpha: float = ..., name: Optional[Any] = ...): ...
def silu(x: Any, name: Optional[Any] = ...): ...
def softmax(x: Any, axis: int = ..., dtype: Optional[Any] = ..., name: Optional[Any] = ...): ...
def softmax_(x: Any, axis: int = ..., dtype: Optional[Any] = ..., name: Optional[Any] = ...): ...
def softplus(x: Any, beta: int = ..., threshold: int = ..., name: Optional[Any] = ...): ...
def softshrink(x: Any, threshold: float = ..., name: Optional[Any] = ...): ...
def softsign(x: Any, name: Optional[Any] = ...): ...
def swish(x: Any, name: Optional[Any] = ...): ...
def mish(x: Any, name: Optional[Any] = ...): ...
def tanhshrink(x: Any, name: Optional[Any] = ...): ...
def thresholded_relu(x: Any, threshold: float = ..., name: Optional[Any] = ...): ...
def log_softmax(x: Any, axis: int = ..., dtype: Optional[Any] = ..., name: Optional[Any] = ...): ...
def glu(x: Any, axis: int = ..., name: Optional[Any] = ...): ...
def gumbel_softmax(x: Any, temperature: float = ..., hard: bool = ..., axis: int = ..., name: Optional[Any] = ...): ...
